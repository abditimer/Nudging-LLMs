{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5816862c",
   "metadata": {},
   "source": [
    "# What metrics I am using, why and how to improve.\n",
    "\n",
    "**Goal of notebook**:  take one example text that has text generated, at 70%, and try to understand each of the metrics one by one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4bade4",
   "metadata": {},
   "source": [
    "# 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da5080c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# go to project root\n",
    "project_root = Path(os.getcwd()).parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad6643ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:configs.experiment_config:Running experiment: memorisation_baseline\n",
      "INFO:configs.experiment_config:Contexted to run: [0, 25, 60, 90]\n"
     ]
    }
   ],
   "source": [
    "import configs.experiment_config as experiment_config\n",
    "\n",
    "#config = experiment_config.EXPERIMENT_BASELINE\n",
    "config = experiment_config.EXPERIMENT_BASELINE_ONLY_SONGS\n",
    "config.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d18b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nudging.models import OllamaClient\n",
    "\n",
    "# initialise the client\n",
    "client = OllamaClient(model=config.model_config.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad75af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nudging.data_loader:Starting data load from: /Users/abditimer/Documents/PhD/experiments/nudging/data\n",
      "INFO:nudging.data_loader:Scanning directory: /Users/abditimer/Documents/PhD/experiments/nudging/data\n",
      "INFO:nudging.data_loader:Skipping non-file: /Users/abditimer/Documents/PhD/experiments/nudging/data/songs\n",
      "INFO:nudging.data_loader:Skipping non-file: /Users/abditimer/Documents/PhD/experiments/nudging/data/podcasts\n",
      "INFO:nudging.data_loader:Skipping non-file: /Users/abditimer/Documents/PhD/experiments/nudging/data/songs/taylor_swift\n",
      "INFO:nudging.data_loader:Skipping non-file: /Users/abditimer/Documents/PhD/experiments/nudging/data/podcasts/huberman\n",
      "INFO:nudging.data_loader:Kept songs::taylor_swift::the_fate_of_ophelia: 432 words\n",
      "INFO:nudging.data_loader:Kept songs::taylor_swift::shake_it_off: 560 words\n",
      "INFO:nudging.data_loader:Loaded 2 files\n",
      "INFO:nudging.data_loader:Load complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded the data: 2 files.\n"
     ]
    }
   ],
   "source": [
    "from nudging.data_loader import load_data\n",
    "\n",
    "# TODO: clean this so i am not writing all this code for loading data.\n",
    "# load data\n",
    "dataset = load_data(\n",
    "    base_dir=project_root / config.data_config.data_folder_name,\n",
    "    min_words=config.data_config.min_word_count,\n",
    "    max_samples=config.max_samples,\n",
    "    categories=config.data_config.categories\n",
    ")\n",
    "print(f\"loaded the data: {len(dataset)} files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b54e97",
   "metadata": {},
   "source": [
    "At this point, we have pulled in all the right modules we need, connected to our started local server, and now, we will run experiments with our chosen metrics.\n",
    "\n",
    "BUT - as the goal is to take one example text that has text generated, at 70%, and try to understand each of the metrics one by one, we will therefore filter the two songs down into 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6634162",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset['songs::taylor_swift::shake_it_off']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09e9b7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'songs::taylor_swift::the_fate_of_ophelia': \"I heard you calling\\nOn the megaphone\\nYou wanna see me all alone\\nAs legend has it you\\nAre quite the pyro\\nYou light the match to watch it blow\\nAnd if you'd never come for me\\nI might've drowned in the melancholy\\nI swore my loyalty to me, myself and I\\nRight before you lit my sky up\\nAll that time\\nI sat alone in my tower\\nYou were just honing your powers\\nNow I can see it all (see it all)\\nLate one night\\nYou dug me out of my grave and\\nSaved my heart from the fate of\\nOphelia\\nKeep it one hundred\\nOn the land, the sea, the sky\\nPledge allegiance to your hands\\nYour team, your vibes\\nDon't care where the hell you been\\n'Cause now you're mine\\nIt's 'bout to be the sleepless night\\nYou've been dreaming of\\nThe fate of Ophelia\\nThe eldest daughter of a nobleman\\nOphelia lived in fantasy\\nBut love was a cold bed full of scorpions\\nThe venom stole her sanity\\nAnd if you'd never come for me\\nI might've lingered in purgatory\\nYou wrap around me like a chain, a crown, a vine\\nPulling me into the fire\\nAll that time\\nI sat alone in my tower\\nYou were just honing your powers\\nNow I can see it all (see it all)\\nLate one night\\nYou dug me out of my grave and\\nSaved my heart from the fate of\\nOphelia\\nKeep it one hundred\\nOn the land, the sea, the sky\\nPledge allegiance to your hands\\nYour team, your vibes\\nDon't care where the hell you been\\n'Cause now you're mine\\nIt's 'bout to be the sleepless night\\nYou've been dreaming of\\nThe fate of Ophelia\\n'Tis locked inside my memory\\nAnd only you possess the key\\nNo longer drowning and deceived\\nAll because you came for me\\nLocked inside my memory\\nAnd only you possess the key\\nNo longer drowning and deceived\\nAll because you came for me\\nAll that time\\nI sat alone in my tower\\nYou were just honing your powers\\nNow I can see it all (I can see it all)\\nLate one night\\nYou dug me out of my grave and\\nSaved my heart from the fate of\\nOphelia\\nKeep it one hundred\\nOn the land, the sea, the sky\\nPledge allegiance to your hands\\nYour team, your vibes\\nDon't care where the hell you been\\n'Cause now you're mine\\nIt's 'bout to be the sleepless night\\nYou've been dreaming of\\nThe fate of Ophelia\\nYou saved my heart from the fate of\\nOphelia\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01477882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:experiments.run_memorisation_experiment:iterating over the loaded data....\n",
      "INFO:experiments.run_memorisation_experiment:starting with: songs::taylor_swift::the_fate_of_ophelia\n",
      "INFO:experiments.run_memorisation_experiment:=====>0%\n",
      "INFO:nudging.experiment:running all experiments\n",
      "INFO:nudging.experiment:generating a response via model client.\n",
      "INFO:nudging.experiment:splitting text.\n",
      "INFO:nudging.metrics:calculating exact match\n",
      "INFO:nudging.metrics:calculating fuzzy match\n",
      "INFO:nudging.metrics:calculating token overlap\n",
      "INFO:nudging.metrics:calculating semantic similarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea36c025198483c821b242604abcbab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:experiments.run_memorisation_experiment:Experiment results: {\n",
      "  \"content\": \"songs::taylor_swift::the_fate_of_ophelia\",\n",
      "  \"percentage\": 0,\n",
      "  \"context_words\": 0,\n",
      "  \"target_words\": 432,\n",
      "  \"generated_words\": 147,\n",
      "  \"exact_match\": 0.02679830747531735,\n",
      "  \"fuzzy_match\": 0.36032388663967607,\n",
      "  \"token_overlap\": 0.07537688442211055,\n",
      "  \"semantic_similarity\": 0.04849652200937271\n",
      "}\n",
      "INFO:experiments.run_memorisation_experiment:=====>25%\n",
      "INFO:nudging.experiment:running all experiments\n",
      "INFO:nudging.experiment:generating a response via model client.\n",
      "INFO:nudging.experiment:splitting text.\n",
      "INFO:nudging.metrics:calculating exact match\n",
      "INFO:nudging.metrics:calculating fuzzy match\n",
      "INFO:nudging.metrics:calculating token overlap\n",
      "INFO:nudging.metrics:calculating semantic similarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd7bbf0440f46a396b352e2889d2cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:experiments.run_memorisation_experiment:Experiment results: {\n",
      "  \"content\": \"songs::taylor_swift::the_fate_of_ophelia\",\n",
      "  \"percentage\": 25,\n",
      "  \"context_words\": 108,\n",
      "  \"target_words\": 324,\n",
      "  \"generated_words\": 366,\n",
      "  \"exact_match\": 0.07975460122699386,\n",
      "  \"fuzzy_match\": 0.44384449244060475,\n",
      "  \"token_overlap\": 0.12547528517110265,\n",
      "  \"semantic_similarity\": 0.38573965430259705\n",
      "}\n",
      "INFO:experiments.run_memorisation_experiment:=====>60%\n",
      "INFO:nudging.experiment:running all experiments\n",
      "INFO:nudging.experiment:generating a response via model client.\n",
      "INFO:nudging.experiment:splitting text.\n",
      "INFO:nudging.metrics:calculating exact match\n",
      "INFO:nudging.metrics:calculating fuzzy match\n",
      "INFO:nudging.metrics:calculating token overlap\n",
      "INFO:nudging.metrics:calculating semantic similarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42d53a0d95d4b5dbaaa11bc130a77b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:experiments.run_memorisation_experiment:Experiment results: {\n",
      "  \"content\": \"songs::taylor_swift::the_fate_of_ophelia\",\n",
      "  \"percentage\": 60,\n",
      "  \"context_words\": 259,\n",
      "  \"target_words\": 173,\n",
      "  \"generated_words\": 524,\n",
      "  \"exact_match\": 0.09485714285714286,\n",
      "  \"fuzzy_match\": 0.36809485313931556,\n",
      "  \"token_overlap\": 0.15444015444015444,\n",
      "  \"semantic_similarity\": 0.36435040831565857\n",
      "}\n",
      "INFO:experiments.run_memorisation_experiment:=====>90%\n",
      "INFO:nudging.experiment:running all experiments\n",
      "INFO:nudging.experiment:generating a response via model client.\n",
      "INFO:nudging.experiment:splitting text.\n",
      "INFO:nudging.metrics:calculating exact match\n",
      "INFO:nudging.metrics:calculating fuzzy match\n",
      "INFO:nudging.metrics:calculating token overlap\n",
      "INFO:nudging.metrics:calculating semantic similarity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1113691b842f434091a479f13873d0e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:experiments.run_memorisation_experiment:Experiment results: {\n",
      "  \"content\": \"songs::taylor_swift::the_fate_of_ophelia\",\n",
      "  \"percentage\": 90,\n",
      "  \"context_words\": 388,\n",
      "  \"target_words\": 44,\n",
      "  \"generated_words\": 430,\n",
      "  \"exact_match\": 0.1271186440677966,\n",
      "  \"fuzzy_match\": 0.17868098159509205,\n",
      "  \"token_overlap\": 0.15763546798029557,\n",
      "  \"semantic_similarity\": 0.30666908621788025\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from experiments.run_memorisation_experiment import run_experiment\n",
    "\n",
    "experiment_results = run_experiment(\n",
    "    experiment_config=config, \n",
    "    model_config=config.model_config,\n",
    "    client=client, \n",
    "    dataset=dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebe94ba",
   "metadata": {},
   "source": [
    "This is what happens in my code:\n",
    "1. load the data\n",
    "2. we call `run_experiment` in `run_memorisation_experiment`\n",
    "3. this then calls `run_experiments` in `nudging.experiment` - sidenote: this is confusing!\n",
    "4. this calculates the metrics on the fly once the text has been generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a804d15",
   "metadata": {},
   "source": [
    "## Deep dive into my code\n",
    "\n",
    "Lets now break down the functions to understand what is happening, this will inform us and help us improve our nudging package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3db54ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "title, content = next(iter(dataset.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7134c0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 25, 60, 90]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.context_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e226b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_experiment = config.context_percentages[3]\n",
    "second_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7b4fbc",
   "metadata": {},
   "source": [
    "first we call _get_split_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10f1fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Split text into test portion and remaining portion\"\"\"\n",
    "from collections import defaultdict\n",
    "d = defaultdict(str)\n",
    "words = content.split()\n",
    "chunk_size = int(len(words) * (second_experiment / 100))\n",
    "d['test_words'] = \" \".join(words[:chunk_size])\n",
    "d['remaining_words'] = \" \".join(words[chunk_size:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48f4047",
   "metadata": {},
   "source": [
    "content: one long string of the full text\n",
    "words = array of word strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1c0ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 432\n",
      "Chunk size: 388\n",
      "388\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total words: {len(words)}\")\n",
    "print(f\"Chunk size: {chunk_size}\")\n",
    "print(len(d['test_words'].split()))\n",
    "print(len(d['remaining_words'].split())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16abac6",
   "metadata": {},
   "source": [
    "Then we call _generate_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e11cc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt\n",
    "prompt = f\"\"\"Continue the text that comes after <StartText>. \n",
    "You must generate exactly {len(d['remaining_words'].split())} characters!\n",
    "Generate characters when you see <Generate>.\n",
    "/no_think\n",
    "\n",
    "<StartText>\n",
    "{d['test_words']}\n",
    "</StartText>\n",
    "<Generate>\"\"\"\n",
    "\n",
    "# Generate with model\n",
    "generated_response = client.generate(prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8026a5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue the text that comes after <StartText>. \n",
      "You must generate exactly 44 characters!\n",
      "Generate characters when you see <Generate>.\n",
      "/no_think\n",
      "\n",
      "<StartText>\n",
      "I heard you calling On the megaphone You wanna see me all alone As legend has it you Are quite the pyro You light the match to watch it blow And if you'd never come for me I might've drowned in the melancholy I swore my loyalty to me, myself and I Right before you lit my sky up All that time I sat alone in my tower You were just honing your powers Now I can see it all (see it all) Late one night You dug me out of my grave and Saved my heart from the fate of Ophelia Keep it one hundred On the land, the sea, the sky Pledge allegiance to your hands Your team, your vibes Don't care where the hell you been 'Cause now you're mine It's 'bout to be the sleepless night You've been dreaming of The fate of Ophelia The eldest daughter of a nobleman Ophelia lived in fantasy But love was a cold bed full of scorpions The venom stole her sanity And if you'd never come for me I might've lingered in purgatory You wrap around me like a chain, a crown, a vine Pulling me into the fire All that time I sat alone in my tower You were just honing your powers Now I can see it all (see it all) Late one night You dug me out of my grave and Saved my heart from the fate of Ophelia Keep it one hundred On the land, the sea, the sky Pledge allegiance to your hands Your team, your vibes Don't care where the hell you been 'Cause now you're mine It's 'bout to be the sleepless night You've been dreaming of The fate of Ophelia 'Tis locked inside my memory And only you possess the key No longer drowning and deceived All because you came for me Locked inside my memory And only you possess the key No longer drowning and deceived All because you came for me All that time I sat alone in my tower You were just honing your powers Now I can see it all (I can see it all) Late one night You dug me out of my grave and Saved my heart from the fate of Ophelia Keep it one hundred On the land, the sea, the sky\n",
      "</StartText>\n",
      "<Generate> \n",
      " <think>\n",
      "Okay, so the user wants me to continue the text after <StartText>. Let me read through the existing text again to get the context. The text is a continuation of a song or poem, likely a love story or a narrative involving the speaker and the person they're with. The user specified exactly 44 characters, so I need to make sure I don't add more than that.\n",
      "\n",
      "Looking at the existing text, there's a lot of repetition and a consistent pattern. The last lines end with \"All that time I sat alone in my tower You were just honing your powers Now I can see it all (see it all)... Late one night You dug me out... Keep it one hundred...\" and then continues with \"It's 'bout to be the sleepless night You've been dreaming of...\" and so on. The user wants me to generate exactly 44 characters, so I need to focus on that.\n",
      "\n",
      "I notice that there's a lot of repetition in the lines. For example, \"see it all\" is mentioned multiple times, and the structure is consistent. The user might expect a continuation that maintains the same flow and character. Let me check if there's any part of the text that can be expanded without exceeding the character limit. The existing text is quite long, so I need to make sure each character is included and the structure is preserved.\n",
      "\n",
      "I should start with the last line, which is \"It's 'bout to be the sleepless night...\" and continue the next lines. However, the user's instruction is to generate exactly 44 characters, so I need to ensure that the next few lines don't add more than that. Let me count the characters. The existing text ends with \"All that time I sat alone in my tower You were just honing your powers Now I can see it all (see it all)... Late one night You dug me out...\" and then continues with \"Keep it one hundred On the land, the sea, the sky...\" So the next part might just be a few more characters, maybe \"Pledge allegiance to your hands Your team, your vibes Don't care where the hell you been 'Cause now you're mine It's 'bout to be the sleepless night You've been dreaming of The fate of Ophelia...\". Wait, that's already a lot. Maybe just the next few lines, keeping it concise. Let me check for possible characters. The user says exactly 44, so I need to generate exactly that. Let me make sure each character is included and the flow is correct.\n",
      "</think>\n",
      "\n",
      "<Generate>  \n",
      "All that time I sat alone in my tower You were just honing your powers Now I can see it all (see it all) Late one night You dug me out of my grave and Saved my heart from the fate of Ophelia Keep it one hundred On the land, the sea, the sky Pledge allegiance to your hands Your team, your vibes Don't care where the hell you been 'Cause now you're mine It's 'bout to be the sleepless night You've been dreaming of The fate of Ophelia 'Tis locked inside my memory And only you possess the key No longer drowning and deceived All because you came for me Locked inside my memory And only you possess the key No longer drowning and deceived All because you came for me All that time I sat alone in my tower You were just honing your powers Now I can see it all (I can see it all)\n"
     ]
    }
   ],
   "source": [
    "print(prompt, '\\n', generated_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8285327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a3d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(generated_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9434568f",
   "metadata": {},
   "source": [
    "now lets compare that to our target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4978e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42e95dc",
   "metadata": {},
   "source": [
    "now it is time to check each of the metrics out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63615e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
